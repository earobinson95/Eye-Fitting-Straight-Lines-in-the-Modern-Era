---
title: "Eye Fitting Straight Lines in the Modern Era"
subtitle: "Data Analysis"
author: "Emily Robinson"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	message = FALSE,
	warning = FALSE
)
library(knitr)
```

<br>

**Rmd file containing code can be accessed [here](https://github.com/earobinson95/Eye-Fitting-Straight-Lines-in-the-Modern-Era/tree/main/analysis).**

## SETUP

+ Load libraries
+ Functions for computing confidence intervals

```{r setup2}
library(tidyverse)
library(kableExtra)
library(readr)
library(here)
library(mgcv)
library(lme4)
library(lmerTest)
library(emmeans)
source(here("analysis/gamm-predict-function.R"))
```

## PARTICIPANT DATA

De-identified participant data collected in the study and used for analyses are available to be downloaded from GitHub [here](https://github.com/earobinson95/Eye-Fitting-Straight-Lines-in-the-Modern-Era/tree/main/data).

```{r data}
eyefitting_model_data  <- read_csv(here("data/youdrawit-eyefitting-model-data.csv"))

factorCols <- c("participantID", "nick_name", "study_starttime", "age", "gender", "academic_study",
                "recruitment", "plotID", "parm_id")
eyefitting_model_data[,factorCols] <- lapply(eyefitting_model_data[,factorCols], factor)
```

```{r data-table, echo = F}
eyefitting_model_data[1:10,] %>%
  kbl() %>%
  kable_paper() %>%
  scroll_box(width = "100%", height = "200px")

eyefitting_model_data <- eyefitting_model_data %>%
  dplyr::mutate(`Parameter Choice` = parm_id)
```

## RAW DATA PLOTS

### OLS with loess smoother

```{r yloess-ols-plot}
eyefitting_model_data %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = yloess, group = plotID), alpha = 0.5, color = "steelblue") +
  geom_line(alpha = 0.2, aes(y = yols, group = participantID)) +
  # geom_line(alpha = 0.2, aes(y = ypca, group = participantID), linetype = "dashed") +
  facet_wrap(~ parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous(limits = c(0, 20)) +
  ggtitle("OLS")
```

### PCA with loess smoother

```{r yloess-pca-plot}
eyefitting_model_data %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = yloess, group = plotID), alpha = 0.5, color = "steelblue") +
  # geom_line(alpha = 0.2, aes(y = yols, group = participantID)) +
  geom_line(alpha = 0.2, aes(y = ypca, group = participantID)) +
  facet_wrap(~ parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous(limits = c(0, 20)) +
  ggtitle("PCA")
```

### Residuals with loess smoother

+ residualols = ydrawn - yols, denoted $e_{ols}$
+ residualpca = ydrawn - ypca, denoted $e_{pca}$

```{r residual-plot}
eyefitting_model_data %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = residualols.loess, group = plotID, color = "OLS"), alpha = 0.3) +
  geom_line(aes(y = residualpca.loess, group = plotID, color = "PCA"), alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_wrap(~parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous(limits = c(0, 20)) +
  scale_color_manual("Estimate", values = c("steelblue", "orange"))
```

## LINEAR CONSTRAINT (Linear Mixed Model)

**Treatments:**

+ parm_ID (S, F, V, N)
+ x (0, 20)

**Response:** raw residuals

+ residualols = ydrawn - yols, denoted $e_{ols}$
+ residualpca = ydrawn - ypca, denoted $e_{pca}$

**Experimental Design:**    

+ Each participant saw each of the 4 plots (new simulated data for each)
    
**ANOVA Table:**

```{r, anova-lmer, echo = F}
sv <- c("participantID", "parm_id", "x", "x:parm_id", "residual")
df <- c("(50 - 1) = 49", "(4 - 1) = 3", "1", "(4 - 1) = 3", "143 - by subtraction")
data.frame("SV" = sv, "DF" = df) %>% kable()
```

**LMM Model:**

$$y_{drawn} - y_{ols} = e_{ij,ols} = \left[\gamma_0 + \alpha_i\right] + \left[\gamma_{1} x_{ij} + \gamma_{2i} x_{ij}\right] + p_{j} + \epsilon_{ij}$$

+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the parameter combination on the intercept (i.e. how much the intercept adjusts for each parameter combo)
+ $\gamma_1$ is the overall slope for x
+ $\gamma_{2i}$ is the effect of the parameter combination on the slope (i.e. think unequal slopes)
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the participant error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.


```{r lmer, fig.height = 9}
# OLS
eyefitting.ols.lmer <- lmer(residualols ~ -1 + parm_id + x:parm_id + (1|participantID),
                       data = eyefitting_model_data)
anova(eyefitting.ols.lmer)

# PCA
eyefitting.pca.lmer <- lmer(residualpca ~ -1 + parm_id + x:parm_id + (1|participantID),
                            data = eyefitting_model_data)
anova(eyefitting.pca.lmer)

# Obtain Predictions
eyefitting.ols.grid.lmer  <- ref_grid(eyefitting.ols.lmer, at = list(x = seq(1,20,0.5)))
eyefitting.ols.preds.lmer <- emmeans(eyefitting.ols.grid.lmer, ~ parm_id:x, cov.reduce = FALSE) %>% 
  as_tibble()

eyefitting.pca.grid.lmer  <- ref_grid(eyefitting.pca.lmer, at = list(x = seq(1,20,0.5)))
eyefitting.pca.preds.lmer <- emmeans(eyefitting.pca.grid.lmer, ~ parm_id:x, cov.reduce = FALSE) %>% 
  as_tibble()

eyefitting.preds.lmer <- eyefitting.ols.preds.lmer %>%
  full_join(eyefitting.pca.preds.lmer, by = c("x", "parm_id"), suffix = c(".ols", ".pca"))

# write.csv(eyefitting.preds.lmer, "results/youdrawit-eyefitting-lmerpred-data.csv", row.names = F, na = "")


# Plot Predictions
eyefitting.lmer.plot <- eyefitting.preds.lmer %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  mutate(parm_id = factor(parm_id, levels = c("S", "F", "V", "N"))) %>%
  dplyr::rename(`Parameter Choice` = parm_id) %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.1) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.1) +
  geom_ribbon(aes(ymin = asymp.LCL.ols, ymax = asymp.UCL.ols, fill = "OLS"), color = NA, alpha = 0.7) +
  geom_line(aes(y = emmean.ols, color = "OLS")) +
  geom_ribbon(aes(ymin = asymp.LCL.pca, ymax = asymp.UCL.pca, fill = "PCA"), color = NA, alpha = 0.7) +
  geom_line(aes(y = emmean.pca, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~`Parameter Choice`, ncol = 2) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "right",
        plot.title   = element_text(size = 12, hjust = 0),
        axis.text    = element_text(size = 12),
        axis.title   = element_text(size = 12),
        legend.title = element_text(size = 12),
        legend.text  = element_text(size = 12),
        # strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
        # strip.background = element_rect(size = 0.5),
        legend.key.size = unit(1, "line")
        ) +
  scale_y_continuous("Residual") +
  scale_color_manual("Individual participant \nresiduals", values = c("steelblue", "orange"), labels = c("OLS", "PCA")) +
  scale_fill_manual("LMER fitted trend", values = c("steelblue", "orange"), labels = c("OLS", "PCA")) 

eyefitting.lmer.plot
```

## SMOOTHING SPLINES (Generalized Additive Mixed Model)

**Treatments:**

+ parm_ID (S, F, V, N)
+ x (0, 20)

**Response:** raw residuals

+ residualols = ydrawn - yols, denoted $e_{ols}$
+ residualpca = ydrawn - ypca, denoted $e_{pca}$

**Experimental Design:**    

+ Each participant saw each of the 4 plots (new simulated data for each)

**GAMM Model: fit = OLS, PCA**

$$y_{ijk, drawn} - \hat y_{ijk, fit} = e_{ijk,fit} = \alpha_i + s_{i}(x_{ijk}) + p_{j} + s_{j}(x_{ijk})$$

+ $y_{ijk,drawn}$ is the drawn y-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of x-value
+ $\hat y_{ijk,fit}$ is the fitted y-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of x-value corresponding to either the OLS or PCA fit
+ $e_{ijk,fit}$ is the residual between the drawn and fitted y-values for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of x-value corresponding to either the OLS or PCA fit
+ $\alpha_i$ is the intercept for the parameter choice $i$
+ $s_{i}$ is the smoothing spline for the $i^{th}$ parameter choice
+ $x_{ijk}$ is the x-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the error due to participant variation
+ $s_{j}$ is the random smoothing spline for each participant.

```{r gamm, fig.height = 9}
# OLS
eyefitting.ols.gamm <- bam(residualols ~ parm_id + s(x, by = parm_id) + 
                             s(participantID, bs = "re") +
                             s(x,participantID, bs = "re"),
            method = "REML",
            data = eyefitting_model_data)

# evaluate gamm
plot(eyefitting.ols.gamm, pages = 1, all.terms=TRUE)

# PCA
eyefitting.pca.gamm <- bam(residualpca ~ -1 + parm_id + s(x) +
                             s(x, by = parm_id) +
                             s(participantID, bs = "re") +
                             s(x,participantID, bs = "re"),
                           method = "REML",
                           data = eyefitting_model_data)
# evaluate gamm
plot(eyefitting.pca.gamm, pages = 1,all.terms=TRUE)

# Obtain Predictions
eyefitting.grid.gamm <- expand_grid(parm_id = c("S", "V", "F", "N"),
                                    x = seq(0,20, 0.5),
                                    participantID = eyefitting_model_data$participantID[1])

# OLS
eyefitting.ols.preds <- predict_gamm(eyefitting.ols.gamm, newdata = eyefitting.grid.gamm, se = T, re_form = NA)
eyefitting.grid.gamm$ols.pred <- eyefitting.ols.preds$prediction
eyefitting.grid.gamm$ols.lower <- eyefitting.ols.preds$prediction - (1.96 * eyefitting.ols.preds$se)
eyefitting.grid.gamm$ols.upper <- eyefitting.ols.preds$prediction + (1.96 * eyefitting.ols.preds$se)

# PCA
eyefitting.pca.preds <- predict_gamm(eyefitting.pca.gamm, newdata = eyefitting.grid.gamm, se = T, re_form = NA)
eyefitting.grid.gamm$pca.pred <- eyefitting.pca.preds$prediction
eyefitting.grid.gamm$pca.lower <- eyefitting.pca.preds$prediction - (1.96 * eyefitting.pca.preds$se)
eyefitting.grid.gamm$pca.upper <- eyefitting.pca.preds$prediction + (1.96 * eyefitting.pca.preds$se)

# write.csv(eyefitting.grid.gamm, "results/youdrawit-eyefitting-gammpred-data.csv", row.names = F, na = "")

# Plot Predictions
eyefitting.gamm.plot <- eyefitting.grid.gamm %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  mutate(parm_id = factor(parm_id, levels = c("S", "F", "V", "N"))) %>%
  dplyr::rename(`Parameter Choice` = parm_id) %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.1) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.1) +
  geom_ribbon(aes(ymin = ols.lower, ymax = ols.upper, fill = "OLS"), color = NA, alpha = 0.5) +
  geom_line(aes(y = ols.pred, color = "OLS")) +
  geom_ribbon(aes(ymin = pca.lower, ymax = pca.upper, fill = "PCA"), color = NA, alpha = 0.5) +
  geom_line(aes(y = pca.pred, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~`Parameter Choice`, ncol = 2) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "right",
        plot.title   = element_text(size = 12, hjust = 0),
        axis.text    = element_text(size = 12),
        axis.title   = element_text(size = 12),
        legend.title = element_text(size = 12),
        legend.text  = element_text(size = 12),
        # strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
        # strip.background = element_rect(size = 0.5),
        legend.key.size = unit(1, "line")
        ) +
  scale_y_continuous("Residual") +
  scale_color_manual("Individual participant \nresiduals", values = c("steelblue", "orange"), labels = c("OLS", "PCA")) +
  scale_fill_manual("GAMM fitted trend", values = c("steelblue", "orange"), labels = c("OLS", "PCA")) 
eyefitting.gamm.plot
```
